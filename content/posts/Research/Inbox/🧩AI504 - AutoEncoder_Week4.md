---
title: <Fill me w/ a compact title>
draft: true
tags:
---
### ğŸ¯ Goal 
The rest of your content lives here. You can use **Markdown** here :)
- Autoencoderë¥¼ PyTorchë¡œ ì‹¤ìŠµí•˜ê¸°

# Contents
## Model ì‹ ì„¸ìš¸ ë•Œ
``` PyTorch
class Autoencoder(nn.Module):

	def __init__(self):
		super(Autoencoder,self).__init__()
		self.encoder = nn.Sequential(
			nn.Linear(784, 100),
			nn.ReLU(), # activation function
			nn.Linear(100, 30),
			nn.ReLU() # activation function
		)

		self.decoder = nn.Sequential(
			nn.Linear(30, 100),
			nn.ReLU(), # activation function
			nn.Linear(100, 784),
			nn.Sigmoid() # activation function
		)

	def forward(self, x): # x: (batch_size, 1, 28, 28)
		batch_size = x.size(0)
		x = x.view(-1, 28*28) # reshape to 784(28*28)-dimensional vector #linearize
		encoded = self.encoder(x) # hidden vector
		out = self.decoder(encoded).view(batch_size, 28,28) # final output. resize to input's size
return out, encoded
```

inputì€ batch_size x 28 x 28ë¡œ ë“¤ì–´ì˜¤ëŠ”ë°,
ëª¨ë¸ ì•ˆ functionì—ì„œëŠ” ê° ì´ë¯¸ì§€ ìƒ˜í”Œì— ëŒ€í•´ì„œë§Œ ìƒê°í•œë‹¤.
ê·¸ëŸ°ë° `forward` í•¨ìˆ˜ì—ì„œëŠ” ì‹¤ì œ batch_sizeê¹Œì§€ ê³ ë ¤í•´ì„œ input output dimensionì„ ê³ ë ¤í•´ì•¼í•œë‹¤.


### visualize MNIST
```PyTorch

encoded = encoded.cpu().detach().numpy() # detachë¥¼ í†µí•´ gradientë¥¼ ê³„ì‚°í•˜ì§€ ì•Šê²Œë”í•¨.
tsne = TSNE()
X_test_2D = tsne.fit_transform(encoded) # tensorë¥¼ 2ì°¨ì› ê°’ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê±°ë˜
X_test_2D = (X_test_2D - X_test_2D.min()) / (X_test_2D.max() - X_test_2D.min()) # min, maxëŠ” xyì¢Œí‘œì˜ min, max

```

## Autoencoder for denoising

inputì— noiseë¥¼ ì£¼ëŠ”ë° ì´ ë•Œ 
`noise = torch.zeros(inputs.size(0), 1, 28, 28`
`nn.init.normal_(noise, 0, 0.1)`
ì„ ê¸°ì–µí•˜ë©´ ë  ê²ƒ ê°™ë‹¤.
```PyTorch
for inputs, labels in dataloaders[phase]:

noise = torch.zeros(inputs.size(0), 1, 28,28) # Add noise to the input

nn.init.normal_(noise, 0, 0.1) # gaussian distribution

noise = noise.to(device)

inputs = inputs.to(device)

noise_inputs = inputs + noise
```