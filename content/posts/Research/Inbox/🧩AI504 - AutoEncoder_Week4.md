---
title: <Fill me w/ a compact title>
draft: true
tags:
---
### ğŸ¯ Goal 
The rest of your content lives here. You can use **Markdown** here :)
- Autoencoderë¥¼ PyTorchë¡œ ì‹¤ìŠµí•˜ê¸°

# Contents
## Model ì‹ ì„¸ìš¸ ë•Œ
``` PyTorch
class Autoencoder(nn.Module):

	def __init__(self):
		super(Autoencoder,self).__init__()
		self.encoder = nn.Sequential(
			nn.Linear(784, 100),
			nn.ReLU(), # activation function
			nn.Linear(100, 30),
			nn.ReLU() # activation function
		)

		self.decoder = nn.Sequential(
			nn.Linear(30, 100),
			nn.ReLU(), # activation function
			nn.Linear(100, 784),
			nn.Sigmoid() # activation function
		)

	def forward(self, x): # x: (batch_size, 1, 28, 28)
		batch_size = x.size(0)
		x = x.view(-1, 28*28) # reshape to 784(28*28)-dimensional vector #linearize
		encoded = self.encoder(x) # hidden vector
		out = self.decoder(encoded).view(batch_size, 28,28) # final output. resize to input's size
return out, encoded
```

inputì€ batch_size x 28 x 28ë¡œ ë“¤ì–´ì˜¤ëŠ”ë°,
ëª¨ë¸ ì•ˆ functionì—ì„œëŠ” ê° ì´ë¯¸ì§€ ìƒ˜í”Œì— ëŒ€í•´ì„œë§Œ ìƒê°í•œë‹¤.
ê·¸ëŸ°ë° `forward` í•¨ìˆ˜ì—ì„œëŠ” ì‹¤ì œ batch_sizeê¹Œì§€ ê³ ë ¤í•´ì„œ input output dimensionì„ ê³ ë ¤í•´ì•¼í•œë‹¤.